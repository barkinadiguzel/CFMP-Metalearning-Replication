# âœ’ï¸ CFMP-MetaLearning-Replication â€” Context- & Relation-Aware Meta-Molecular Model

This repository provides a **PyTorch replication** of the **CFMP-MetaMol architecture**, reproducing the paperâ€™s **mathematics, block diagrams, and meta-learning structure**.  

It implements **meta-learning over molecular graphs** with **context-informed embeddings** and **relation-aware updates**, using a **single meta_model** to handle both inner- and outer-loop adaptation.  

Focus is on understanding:

- How **atom/bond embeddings** propagate through the GNN encoder ðŸ§©  
- How **KNN graph reduction** and **relation graphs** enhance context representation ðŸŒ  
- How **inner-loop adaptation** quickly updates task-specific embeddings and  
  **outer-loop meta-gradients** optimize generalization across tasks (We didn't replicate the train part,so we didn't put inner and outer loop int this repo) ðŸ”„  

Paper reference: [CFMP-MetaMol: Context- and Relation-Aware Meta-Learning for Molecular Property Prediction](https://pmc.ncbi.nlm.nih.gov/articles/PMC12510055/#se0020)

---

## Overview â€” Meta-Molecular Learning âœ¦

![CFMP-MetaMol Overview](images/figmix.jpg)

> Molecular properties are learned from atom types, positions, and relational context across tasks.

The model integrates:

- **GNN encoder** for atom/bond embeddings  
- **KNN graph reduction** to focus on local neighbors  
- **Relation-aware embedding updates** with self-attention  
- **Prototype-based classifier** for few-shot molecular property prediction  
- **Inner-loop** adaptation for task-specific quick updates  
- **Outer-loop** meta-gradient updates for generalization  

---

## Molecular Representation âš—ï¸Ž

A molecule is represented by:

$$
G = (V, E), \quad X = \{x_i\}_{i=1}^N
$$

with atom/bond features projected as:

$$
H^0_i = \text{Encoder}(x_i, G)
$$

---

## Context & Relation Modeling ðŸŒ

- **KNN graph** reduces neighbors to relevant context:  
$$\tilde{G} = \text{KNN}(H^0)$$

- **Relation graph** captures task-aware interactions:  
$$R = f_\text{relation}(\tilde{G})$$

- **Relation-aware embedding update**:  
$$H^{l+1} = H^l + \text{RelationUpdate}(H^l, R)$$

- **Neighbor alignment regularizer** encourages consistent embeddings:
  
$$L_\text{neighbor} = \sum_i \Big\| H_i - \frac{1}{|\mathcal{N}(i)|} \sum_{j \in \mathcal{N}(i)} H_j \Big\|^2$$


---

## Classifier & Prototype âš¡

- Class prototypes computed from support set:  
$$P_c = \frac{1}{|S_c|} \sum_{i \in S_c} H_i$$

- Query molecule classification via distance to prototypes:  
$$\hat{y} = \text{softmax}(-d(H_q, P_c))$$

- Loss includes **CrossEntropy** and **neighbor regularization**:

$$
L = L_\text{CE} + \lambda \, L_\text{neighbor}
$$

---

## Meta-Learning Loops ðŸ”„

- **Inner loop** (task-specific adaptation):

$$
H'_i = H_i - \alpha \, \nabla_{H_i} L_\text{task}(H_i)
$$


- **Outer loop** (meta-gradient update across tasks):
  
$$\theta \;=\; \theta - \beta \cdot \frac{\partial}{\partial \theta} \sum_{\text{tasks}} L_\text{task}(H'_i)$$


> Inner loop adapts embeddings quickly per task, outer loop optimizes the overall model parameters for generalization.

---

## Why CFMP-Metalearning-Replication Matters ðŸ§ª

- Handles **few-shot molecular property prediction**  
- Leverages **context-aware GNN embeddings**  
- Integrates **relation graphs and neighbor regularization** for structural bias  
- Minimal, readable implementation for **replication and educational purposes**

---

## Repository Structure ðŸ—‚

```bash
CFMP-MetaLearning-Replication/
â”œâ”€â”€ src/
â”‚
â”‚   â”œâ”€â”€ encoder/
â”‚   â”‚   â”œâ”€â”€ gnn_encoder.py        # H = Encoder(G)  (embedding)
â”‚   â”‚   â””â”€â”€ atom_bond_embed.py    # Atom/bond feature projection
â”‚
â”‚   â”œâ”€â”€ context_model/
â”‚   â”‚   â”œâ”€â”€ knn_graph.py          # KNN graph reduction
â”‚   â”‚   â”œâ”€â”€ relation_graph.py     # Relation graph creation
â”‚   â”‚   â”œâ”€â”€ relation_update.py    # Relation-aware embedding update
â”‚   â”‚   â””â”€â”€ neighbor_reg.py       # Neighbor alignment regularizer loss
â”‚
â”‚   â”œâ”€â”€ classifier/
â”‚   â”‚   â””â”€â”€ classifier.py         # Prototype-based classifier (Eq. 8)
â”‚
â”‚   â”œâ”€â”€ meta_learning/
â”‚   â”‚   â””â”€â”€ meta_model.py         # Full forward: encoderâ†’contextâ†’classifier
â”‚
â”‚   â””â”€â”€ config.py                 # Paper hyperparameters
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ figmix.jpg                # Model overview figure
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---


## ðŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
